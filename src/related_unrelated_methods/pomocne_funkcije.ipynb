{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import enchant\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import string\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from scipy import spatial\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datoteka_za_rad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49967</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Pizza delivery man gets tipped more than $2,00...</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49968</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Pizza delivery man gets $2,000 tip</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49969</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49970</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49972 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Body ID                                        articleBody  \\\n",
       "0            0  A small meteorite crashed into a wooded area i...   \n",
       "1            0  A small meteorite crashed into a wooded area i...   \n",
       "2            0  A small meteorite crashed into a wooded area i...   \n",
       "3            0  A small meteorite crashed into a wooded area i...   \n",
       "4            0  A small meteorite crashed into a wooded area i...   \n",
       "...        ...                                                ...   \n",
       "49967     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49968     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49969     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49970     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49971     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "\n",
       "                                                Headline     Stance  \n",
       "0      Soldier shot, Parliament locked down after gun...  unrelated  \n",
       "1      Tourist dubbed ‘Spider Man’ after spider burro...  unrelated  \n",
       "2      Luke Somers 'killed in failed rescue attempt i...  unrelated  \n",
       "3       BREAKING: Soldier shot at War Memorial in Ottawa  unrelated  \n",
       "4      Giant 8ft 9in catfish weighing 19 stone caught...  unrelated  \n",
       "...                                                  ...        ...  \n",
       "49967  Pizza delivery man gets tipped more than $2,00...    related  \n",
       "49968                 Pizza delivery man gets $2,000 tip    related  \n",
       "49969   Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip    related  \n",
       "49970  Ann Arbor pizza delivery driver surprised with...    related  \n",
       "49971  Ann Arbor pizza delivery driver surprised with...    related  \n",
       "\n",
       "[49972 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim - remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick likes play football, fond tennis.\n"
     ]
    }
   ],
   "source": [
    "#from gensim.parsing.preprocessing import remove_stopwords\n",
    "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
    "filtered_sentence = remove_stopwords(text)\n",
    "\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metoda = GLOVE model\n",
    "https://stackoverflow.com/questions/65852710/text-similarity-using-word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import spatial\n",
    "#import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0 vs s1 -> 0.965923011302948\n",
      "s0 vs s2 -> 0.8659112453460693\n",
      "s0 vs s3 -> 0.5877998471260071\n"
     ]
    }
   ],
   "source": [
    "s0 = 'Mark zuckerberg owns the facebook company'\n",
    "s1 = 'Facebook company ceo is mark zuckerberg'\n",
    "s2 = 'Microsoft is owned by Bill gates'\n",
    "s3 = 'How to learn japanese'\n",
    "\n",
    "def preprocess(s):\n",
    "    return [i.lower() for i in s.split()]\n",
    "\n",
    "def get_vector(s):\n",
    "    return np.sum(np.array([model[i] for i in preprocess(s)]), axis=0)\n",
    "\n",
    "\n",
    "print('s0 vs s1 ->',1 - spatial.distance.cosine(get_vector(s0), get_vector(s1)))\n",
    "print('s0 vs s2 ->', 1 - spatial.distance.cosine(get_vector(s0), get_vector(s2)))\n",
    "print('s0 vs s3 ->', 1 - spatial.distance.cosine(get_vector(s0), get_vector(s3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stopwords\n",
    "Prvo pretvori u lower pa onda makni stopwords. Inače ostanu one s velikim početnim slovom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small meteorite crashed wooded area nicaragua's capital managua overnight, government said sunday.\n",
      "\n",
      "\n",
      "A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\n"
     ]
    }
   ],
   "source": [
    "#remove_stopwords(row['articleBody'].lower())\n",
    "\n",
    "df.reset_index()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for sentence in split_into_sentences(row['articleBody']):\n",
    "        print(remove_stopwords(sentence.lower()))\n",
    "        print('\\n')\n",
    "        print(sentence)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi what is the weather like\n"
     ]
    }
   ],
   "source": [
    "a_string = '!hi. wh?at is the weat[h]er lik?e.'\n",
    "\n",
    "new_string = a_string.translate(str.maketrans('', '', string.punctuation))\n",
    "print(new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into sentences + remove stopwards + remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small meteorite crashed wooded area nicaraguas capital managua overnight government said sunday\n"
     ]
    }
   ],
   "source": [
    "df.reset_index()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for sentence in split_into_sentences(row['articleBody']):\n",
    "        #remove punctuation\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        #make lowercase\n",
    "        sentence = sentence.lower()\n",
    "        \n",
    "        #remove stopwords\n",
    "        sentence = remove_stopwords(sentence)\n",
    "        \n",
    "        #print\n",
    "        print(sentence)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small meteorite crashed wooded area nicaraguas capital managua overnight government said sunday\n"
     ]
    }
   ],
   "source": [
    "# in short:\n",
    "\n",
    "df.reset_index()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for sentence in split_into_sentences(row['articleBody']):\n",
    "        #remove all\n",
    "        sentence = remove_stopwords(sentence.translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "        \n",
    "        #print\n",
    "        print(sentence)\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vjezbe",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
