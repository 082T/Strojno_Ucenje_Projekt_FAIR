{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies_data = pd.read_csv('fnc-1/train_bodies.csv')\n",
    "train_stances_data = pd.read_csv('fnc-1/train_stances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stances_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49967</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Pizza delivery man gets tipped more than $2,00...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49968</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Pizza delivery man gets $2,000 tip</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49969</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49970</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49972 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Body ID                                        articleBody  \\\n",
       "0            0  A small meteorite crashed into a wooded area i...   \n",
       "1            0  A small meteorite crashed into a wooded area i...   \n",
       "2            0  A small meteorite crashed into a wooded area i...   \n",
       "3            0  A small meteorite crashed into a wooded area i...   \n",
       "4            0  A small meteorite crashed into a wooded area i...   \n",
       "...        ...                                                ...   \n",
       "49967     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49968     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49969     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49970     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49971     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "\n",
       "                                                Headline     Stance  \n",
       "0      Soldier shot, Parliament locked down after gun...  unrelated  \n",
       "1      Tourist dubbed ‘Spider Man’ after spider burro...  unrelated  \n",
       "2      Luke Somers 'killed in failed rescue attempt i...  unrelated  \n",
       "3       BREAKING: Soldier shot at War Memorial in Ottawa  unrelated  \n",
       "4      Giant 8ft 9in catfish weighing 19 stone caught...  unrelated  \n",
       "...                                                  ...        ...  \n",
       "49967  Pizza delivery man gets tipped more than $2,00...      agree  \n",
       "49968                 Pizza delivery man gets $2,000 tip      agree  \n",
       "49969   Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip      agree  \n",
       "49970  Ann Arbor pizza delivery driver surprised with...      agree  \n",
       "49971  Ann Arbor pizza delivery driver surprised with...      agree  \n",
       "\n",
       "[49972 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.merge(train_bodies_data, train_stances_data, left_on = 'Body ID', right_on = 'Body ID')\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Small Meteorite Strikes in Nicaragua's Capital...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "      <td>It Begins: HazMat-Wearing Passenger Spotted At...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "      <td>20-Year-Old Quarter Pounder Looks About the Same</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "      <td>Two blokes dared to eat 20-year-old burger for...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "      <td>‘The cub of Baghdadi': ISIS reports its younge...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49967</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Pizza delivery man gets tipped more than $2,00...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49968</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Pizza delivery man gets $2,000 tip</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49969</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49970</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>2532</td>\n",
       "      <td>ANN ARBOR, Mich. – A pizza delivery man in Mic...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13427 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Body ID                                        articleBody  \\\n",
       "24           0  A small meteorite crashed into a wooded area i...   \n",
       "36           4  Last week we hinted at what was to come as Ebo...   \n",
       "69           5  (NEWSER) – Wonder how long a Quarter Pounder w...   \n",
       "88           5  (NEWSER) – Wonder how long a Quarter Pounder w...   \n",
       "93           6  Posting photos of a gun-toting child online, I...   \n",
       "...        ...                                                ...   \n",
       "49967     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49968     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49969     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49970     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "49971     2532  ANN ARBOR, Mich. – A pizza delivery man in Mic...   \n",
       "\n",
       "                                                Headline   Stance  \n",
       "24     Small Meteorite Strikes in Nicaragua's Capital...    agree  \n",
       "36     It Begins: HazMat-Wearing Passenger Spotted At...  discuss  \n",
       "69      20-Year-Old Quarter Pounder Looks About the Same  discuss  \n",
       "88     Two blokes dared to eat 20-year-old burger for...  discuss  \n",
       "93     ‘The cub of Baghdadi': ISIS reports its younge...  discuss  \n",
       "...                                                  ...      ...  \n",
       "49967  Pizza delivery man gets tipped more than $2,00...    agree  \n",
       "49968                 Pizza delivery man gets $2,000 tip    agree  \n",
       "49969   Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip    agree  \n",
       "49970  Ann Arbor pizza delivery driver surprised with...    agree  \n",
       "49971  Ann Arbor pizza delivery driver surprised with...    agree  \n",
       "\n",
       "[13427 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_df = df_all[df_all.Stance != 'unrelated']\n",
    "related_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns = ['Sentence', 'Headline', 'Stance'])\n",
    "val_df = pd.DataFrame(columns = ['Sentence', 'Headline', 'Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_df.reset_index()\n",
    "\n",
    "i = 0\n",
    "k = 0\n",
    "t = 1\n",
    "for index, row in related_df.iterrows():\n",
    "    sentences = split_into_sentences(row['articleBody'])    \n",
    "\n",
    "    if(len(sentences) != 0):\n",
    "        sentence = sentences[0]\n",
    "        j = 1\n",
    "        while(len(sentence.split()) < 7):\n",
    "            if(j >= len(sentences)):\n",
    "                break\n",
    "            sentence += sentences[j]\n",
    "            j += 1\n",
    "    else:\n",
    "        sentence = row['articleBody']\n",
    "\n",
    "    if(t < 5):\n",
    "        train_df.loc[i] = [sentence, row['Headline'], row['Stance']]\n",
    "        t += 1\n",
    "        i += 1\n",
    "    else:\n",
    "        val_df.loc[k] = [sentence, row['Headline'], row['Stance']]\n",
    "        t = 1\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Small Meteorite Strikes in Nicaragua's Capital...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "      <td>It Begins: HazMat-Wearing Passenger Spotted At...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "      <td>20-Year-Old Quarter Pounder Looks About the Same</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "      <td>Two blokes dared to eat 20-year-old burger for...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "      <td>Insurgents killed in Nigeria despite alleged t...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10737</th>\n",
       "      <td>ANN ARBOR, Mich.– A pizza delivery man in Mich...</td>\n",
       "      <td>Pizza delivery driver surprised with $2,000 tip</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10738</th>\n",
       "      <td>ANN ARBOR, Mich.– A pizza delivery man in Mich...</td>\n",
       "      <td>Pizza delivery man gets tipped more than $2,00...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10739</th>\n",
       "      <td>ANN ARBOR, Mich.– A pizza delivery man in Mich...</td>\n",
       "      <td>Pizza delivery man gets $2,000 tip</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10740</th>\n",
       "      <td>ANN ARBOR, Mich.– A pizza delivery man in Mich...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10741</th>\n",
       "      <td>ANN ARBOR, Mich.– A pizza delivery man in Mich...</td>\n",
       "      <td>Ann Arbor pizza delivery driver surprised with...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  \\\n",
       "0      A small meteorite crashed into a wooded area i...   \n",
       "1      Last week we hinted at what was to come as Ebo...   \n",
       "2      (NEWSER) – Wonder how long a Quarter Pounder w...   \n",
       "3      (NEWSER) – Wonder how long a Quarter Pounder w...   \n",
       "4      At least 25 suspected Boko Haram insurgents we...   \n",
       "...                                                  ...   \n",
       "10737  ANN ARBOR, Mich.– A pizza delivery man in Mich...   \n",
       "10738  ANN ARBOR, Mich.– A pizza delivery man in Mich...   \n",
       "10739  ANN ARBOR, Mich.– A pizza delivery man in Mich...   \n",
       "10740  ANN ARBOR, Mich.– A pizza delivery man in Mich...   \n",
       "10741  ANN ARBOR, Mich.– A pizza delivery man in Mich...   \n",
       "\n",
       "                                                Headline   Stance  \n",
       "0      Small Meteorite Strikes in Nicaragua's Capital...    agree  \n",
       "1      It Begins: HazMat-Wearing Passenger Spotted At...  discuss  \n",
       "2       20-Year-Old Quarter Pounder Looks About the Same  discuss  \n",
       "3      Two blokes dared to eat 20-year-old burger for...  discuss  \n",
       "4      Insurgents killed in Nigeria despite alleged t...  discuss  \n",
       "...                                                  ...      ...  \n",
       "10737    Pizza delivery driver surprised with $2,000 tip    agree  \n",
       "10738  Pizza delivery man gets tipped more than $2,00...    agree  \n",
       "10739                 Pizza delivery man gets $2,000 tip    agree  \n",
       "10740  Ann Arbor pizza delivery driver surprised with...    agree  \n",
       "10741  Ann Arbor pizza delivery driver surprised with...    agree  \n",
       "\n",
       "[10742 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "      <td>‘The cub of Baghdadi': ISIS reports its younge...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- A meteorite crashed down in Managua, ...</td>\n",
       "      <td>Small Meteorite Strikes in Nicaragua's Capital...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mboxCreate('FoxNews-Politics-Autoplay-Videos-I...</td>\n",
       "      <td>US probing claims ISIS fighters seized airdrop...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO's subscription streaming service will be c...</td>\n",
       "      <td>HBO streaming service could launch in April fo...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eran Cicurel, an editor at Voice of Israel, ha...</td>\n",
       "      <td>YPG Confirms: Gill Rosenberg Not Captured in K...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>More than 200 schoolgirls were kidnapped in Ap...</td>\n",
       "      <td>Nigeria claims deal with Boko Haram on ceasefi...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>More than 200 schoolgirls were kidnapped in Ap...</td>\n",
       "      <td>Boko Haram claims to have German hostage, deni...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>A Guantanamo Bay prisoner released last year a...</td>\n",
       "      <td>Senator: Detainees swapped for Bergdahl have c...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>A Guantanamo Bay prisoner released last year a...</td>\n",
       "      <td>Official: Gitmo prisoner traded for Bergdahl r...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>ANN ARBOR, Mich.– A pizza delivery man in Mich...</td>\n",
       "      <td>Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2685 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  \\\n",
       "0     Posting photos of a gun-toting child online, I...   \n",
       "1     (CNN) -- A meteorite crashed down in Managua, ...   \n",
       "2     mboxCreate('FoxNews-Politics-Autoplay-Videos-I...   \n",
       "3     HBO's subscription streaming service will be c...   \n",
       "4     Eran Cicurel, an editor at Voice of Israel, ha...   \n",
       "...                                                 ...   \n",
       "2680  More than 200 schoolgirls were kidnapped in Ap...   \n",
       "2681  More than 200 schoolgirls were kidnapped in Ap...   \n",
       "2682  A Guantanamo Bay prisoner released last year a...   \n",
       "2683  A Guantanamo Bay prisoner released last year a...   \n",
       "2684  ANN ARBOR, Mich.– A pizza delivery man in Mich...   \n",
       "\n",
       "                                               Headline   Stance  \n",
       "0     ‘The cub of Baghdadi': ISIS reports its younge...  discuss  \n",
       "1     Small Meteorite Strikes in Nicaragua's Capital...    agree  \n",
       "2     US probing claims ISIS fighters seized airdrop...  discuss  \n",
       "3     HBO streaming service could launch in April fo...  discuss  \n",
       "4     YPG Confirms: Gill Rosenberg Not Captured in K...    agree  \n",
       "...                                                 ...      ...  \n",
       "2680  Nigeria claims deal with Boko Haram on ceasefi...  discuss  \n",
       "2681  Boko Haram claims to have German hostage, deni...  discuss  \n",
       "2682  Senator: Detainees swapped for Bergdahl have c...  discuss  \n",
       "2683  Official: Gitmo prisoner traded for Bergdahl r...  discuss  \n",
       "2684   Luckiest Pizza Delivery Guy Ever Gets $2,000 Tip    agree  \n",
       "\n",
       "[2685 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10742\n",
      "2685\n"
     ]
    }
   ],
   "source": [
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df):\n",
    "    self.label_dict = {'disagree': 0, 'discuss': 1, 'agree': 2}\n",
    "\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "\n",
    "    self.base_path = '/content/'\n",
    "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.train_data = self.load_data(self.train_df)\n",
    "    self.val_data = self.load_data(self.val_df)\n",
    "\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512\n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['Sentence'].to_list()\n",
    "    hypothesis_list = df['Headline'].to_list()\n",
    "    label_list = df['Stance'].to_list()\n",
    "\n",
    "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=25, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n",
    "  \n",
    "mnli_dataset = MNLIDataBert(train_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = mnli_dataset.get_data_loaders(batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roko\\anaconda3\\envs\\withcuda\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 109,484,547 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer):  \n",
    "  total_step = len(train_loader)\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "\n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "    model.eval()\n",
    "    total_val_acc  = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "\n",
    "        # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "        loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "        \n",
    "        # loss = criterion(prediction, labels)\n",
    "        acc = multi_acc(prediction, labels)\n",
    "\n",
    "        total_val_loss += loss.item()\n",
    "        total_val_acc  += acc.item()\n",
    "\n",
    "    val_acc  = total_val_acc/len(val_loader)\n",
    "    val_loss = total_val_loss/len(val_loader)\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.4919 train_acc: 0.8075 | val_loss: 0.2652 val_acc: 0.9103\n",
      "00:12:02.28\n",
      "Epoch 2: train_loss: 0.1518 train_acc: 0.9485 | val_loss: 0.1394 val_acc: 0.9567\n",
      "00:13:30.68\n",
      "Epoch 3: train_loss: 0.0550 train_acc: 0.9834 | val_loss: 0.1011 val_acc: 0.9748\n",
      "00:17:41.53\n",
      "Epoch 4: train_loss: 0.0395 train_acc: 0.9873 | val_loss: 0.1134 val_acc: 0.9709\n",
      "00:22:31.75\n",
      "Epoch 5: train_loss: 0.0213 train_acc: 0.9936 | val_loss: 0.0935 val_acc: 0.9809\n",
      "00:19:44.19\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"mymodel.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_bodies = pd.read_csv('fnc-1/competition_test_bodies.csv')\n",
    "comp_stances = pd.read_csv('fnc-1/competition_test_stances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>Apple installing safes in-store to protect gol...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>El-Sisi denies claims he'll give Sinai land to...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>Apple to keep gold Watch Editions in special i...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>Apple Stores to Keep Gold “Edition” Apple Watc...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>South Korean woman's hair 'eaten' by robot vac...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25408</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25409</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Republicans call Obamacare a 'failure.' These ...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25410</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>CBO’s Alternate Facts Show Obamacare is Unsust...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25411</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25412</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25413 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Body ID                                        articleBody  \\\n",
       "0            1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "1            1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "2            1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "3            1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "4            1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "...        ...                                                ...   \n",
       "25408     2586  Remember how much Republicans wanted to repeal...   \n",
       "25409     2586  Remember how much Republicans wanted to repeal...   \n",
       "25410     2586  Remember how much Republicans wanted to repeal...   \n",
       "25411     2586  Remember how much Republicans wanted to repeal...   \n",
       "25412     2586  Remember how much Republicans wanted to repeal...   \n",
       "\n",
       "                                                Headline     Stance  \n",
       "0      Apple installing safes in-store to protect gol...  unrelated  \n",
       "1      El-Sisi denies claims he'll give Sinai land to...      agree  \n",
       "2      Apple to keep gold Watch Editions in special i...  unrelated  \n",
       "3      Apple Stores to Keep Gold “Edition” Apple Watc...  unrelated  \n",
       "4      South Korean woman's hair 'eaten' by robot vac...  unrelated  \n",
       "...                                                  ...        ...  \n",
       "25408        A Sign That Obamacare Exchanges Are Failing   disagree  \n",
       "25409  Republicans call Obamacare a 'failure.' These ...      agree  \n",
       "25410  CBO’s Alternate Facts Show Obamacare is Unsust...   disagree  \n",
       "25411                               Why Obamacare failed   disagree  \n",
       "25412  The success of the Affordable Care Act is a hu...      agree  \n",
       "\n",
       "[25413 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_merged = pd.merge(comp_bodies, comp_stances, left_on = 'Body ID', right_on = 'Body ID')\n",
    "comp_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>El-Sisi denies claims he'll give Sinai land to...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
       "      <td>Afghan Mother Kills 25 Taliban Fighters In Sev...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3</td>\n",
       "      <td>CNBC is reporting Tesla has chosen Nevada as t...</td>\n",
       "      <td>REPORT: Tesla Chooses Nevada For Site Of Its M...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>12</td>\n",
       "      <td>A 4-inch version of the iPhone 6 is said to be...</td>\n",
       "      <td>4-inch iPhone 6 reported to be in development</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>19</td>\n",
       "      <td>GR editor’s Note\\n\\nThere are no reports in th...</td>\n",
       "      <td>Iraqi Army Downs Two British Planes Carrying W...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25408</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25409</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Republicans call Obamacare a 'failure.' These ...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25410</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>CBO’s Alternate Facts Show Obamacare is Unsust...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25411</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25412</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7064 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Body ID                                        articleBody  \\\n",
       "1            1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "34           2  A bereaved Afghan mother took revenge on the T...   \n",
       "107          3  CNBC is reporting Tesla has chosen Nevada as t...   \n",
       "201         12  A 4-inch version of the iPhone 6 is said to be...   \n",
       "208         19  GR editor’s Note\\n\\nThere are no reports in th...   \n",
       "...        ...                                                ...   \n",
       "25408     2586  Remember how much Republicans wanted to repeal...   \n",
       "25409     2586  Remember how much Republicans wanted to repeal...   \n",
       "25410     2586  Remember how much Republicans wanted to repeal...   \n",
       "25411     2586  Remember how much Republicans wanted to repeal...   \n",
       "25412     2586  Remember how much Republicans wanted to repeal...   \n",
       "\n",
       "                                                Headline    Stance  \n",
       "1      El-Sisi denies claims he'll give Sinai land to...     agree  \n",
       "34     Afghan Mother Kills 25 Taliban Fighters In Sev...     agree  \n",
       "107    REPORT: Tesla Chooses Nevada For Site Of Its M...   discuss  \n",
       "201        4-inch iPhone 6 reported to be in development   discuss  \n",
       "208    Iraqi Army Downs Two British Planes Carrying W...   discuss  \n",
       "...                                                  ...       ...  \n",
       "25408        A Sign That Obamacare Exchanges Are Failing  disagree  \n",
       "25409  Republicans call Obamacare a 'failure.' These ...     agree  \n",
       "25410  CBO’s Alternate Facts Show Obamacare is Unsust...  disagree  \n",
       "25411                               Why Obamacare failed  disagree  \n",
       "25412  The success of the Affordable Care Act is a hu...     agree  \n",
       "\n",
       "[7064 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_merged_related = comp_merged[comp_merged.Stance != 'unrelated']\n",
    "comp_merged_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = TextClassificationPipeline(model=model, \n",
    "                                  tokenizer=BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True),\n",
    "                                  device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_df = pd.DataFrame(columns = ['Guess'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roko\\anaconda3\\envs\\withcuda\\lib\\site-packages\\transformers\\pipelines\\base.py:978: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "comp_merged_related.reset_index()\n",
    "guess_df.reset_index()\n",
    "\n",
    "tok = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "i = 0\n",
    "for index, row in comp_merged_related.iterrows():\n",
    "    \n",
    "    sentences = split_into_sentences(row['articleBody'])    \n",
    "\n",
    "    if(len(sentences) != 0):\n",
    "        sentence = sentences[0]\n",
    "        j = 1\n",
    "        while(len(sentence.split()) < 7):\n",
    "            if(j >= len(sentences)):\n",
    "                break\n",
    "            sentence += sentences[j]\n",
    "            j += 1\n",
    "    else:\n",
    "        sentence = row['articleBody']\n",
    "        \n",
    "        \n",
    "    sentence_id = tok.encode(sentence, add_special_tokens = False)\n",
    "    headline_id = tok.encode(row['Headline'], add_special_tokens = False)\n",
    "    merged_sentence = \"[CLS] \" + sentence + \" [SEP] \" + row['Headline'] + \" [SEP]\"\n",
    "    \n",
    "    t = (pipe(merged_sentence)[0]['label'])\n",
    "    if (t=='LABEL_0'):\n",
    "        guess_df.loc[i] = 'disagree'\n",
    "    elif (t == 'LABEL_1'):\n",
    "        guess_df.loc[i] = 'discuss'\n",
    "    else:\n",
    "        guess_df.loc[i] = 'agree'\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_clean = pd.DataFrame(columns = ['Body ID', 'articleBody', 'Headline', 'Stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_merged_related.reset_index()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for index, row in comp_merged_related.iterrows():\n",
    "    comp_clean.loc[i] = [row['Body ID'], row['articleBody'], row['Headline'], row['Stance']]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>El-Sisi denies claims he'll give Sinai land to...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
       "      <td>Afghan Mother Kills 25 Taliban Fighters In Sev...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CNBC is reporting Tesla has chosen Nevada as t...</td>\n",
       "      <td>REPORT: Tesla Chooses Nevada For Site Of Its M...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A 4-inch version of the iPhone 6 is said to be...</td>\n",
       "      <td>4-inch iPhone 6 reported to be in development</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>GR editor’s Note\\n\\nThere are no reports in th...</td>\n",
       "      <td>Iraqi Army Downs Two British Planes Carrying W...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7060</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Republicans call Obamacare a 'failure.' These ...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>CBO’s Alternate Facts Show Obamacare is Unsust...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7064 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Body ID                                        articleBody  \\\n",
       "0          1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "1          2  A bereaved Afghan mother took revenge on the T...   \n",
       "2          3  CNBC is reporting Tesla has chosen Nevada as t...   \n",
       "3         12  A 4-inch version of the iPhone 6 is said to be...   \n",
       "4         19  GR editor’s Note\\n\\nThere are no reports in th...   \n",
       "...      ...                                                ...   \n",
       "7059    2586  Remember how much Republicans wanted to repeal...   \n",
       "7060    2586  Remember how much Republicans wanted to repeal...   \n",
       "7061    2586  Remember how much Republicans wanted to repeal...   \n",
       "7062    2586  Remember how much Republicans wanted to repeal...   \n",
       "7063    2586  Remember how much Republicans wanted to repeal...   \n",
       "\n",
       "                                               Headline    Stance  \n",
       "0     El-Sisi denies claims he'll give Sinai land to...     agree  \n",
       "1     Afghan Mother Kills 25 Taliban Fighters In Sev...     agree  \n",
       "2     REPORT: Tesla Chooses Nevada For Site Of Its M...   discuss  \n",
       "3         4-inch iPhone 6 reported to be in development   discuss  \n",
       "4     Iraqi Army Downs Two British Planes Carrying W...   discuss  \n",
       "...                                                 ...       ...  \n",
       "7059        A Sign That Obamacare Exchanges Are Failing  disagree  \n",
       "7060  Republicans call Obamacare a 'failure.' These ...     agree  \n",
       "7061  CBO’s Alternate Facts Show Obamacare is Unsust...  disagree  \n",
       "7062                               Why Obamacare failed  disagree  \n",
       "7063  The success of the Affordable Care Act is a hu...     agree  \n",
       "\n",
       "[7064 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7060</th>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7064 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Guess\n",
       "0     disagree\n",
       "1        agree\n",
       "2      discuss\n",
       "3      discuss\n",
       "4      discuss\n",
       "...        ...\n",
       "7059     agree\n",
       "7060  disagree\n",
       "7061     agree\n",
       "7062     agree\n",
       "7063     agree\n",
       "\n",
       "[7064 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_clean = comp_clean.join(guess_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>El-Sisi denies claims he'll give Sinai land to...</td>\n",
       "      <td>agree</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
       "      <td>Afghan Mother Kills 25 Taliban Fighters In Sev...</td>\n",
       "      <td>agree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CNBC is reporting Tesla has chosen Nevada as t...</td>\n",
       "      <td>REPORT: Tesla Chooses Nevada For Site Of Its M...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A 4-inch version of the iPhone 6 is said to be...</td>\n",
       "      <td>4-inch iPhone 6 reported to be in development</td>\n",
       "      <td>discuss</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>GR editor’s Note\\n\\nThere are no reports in th...</td>\n",
       "      <td>Iraqi Army Downs Two British Planes Carrying W...</td>\n",
       "      <td>discuss</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>disagree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7060</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Republicans call Obamacare a 'failure.' These ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>CBO’s Alternate Facts Show Obamacare is Unsust...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>disagree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>2586</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>agree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7064 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Body ID                                        articleBody  \\\n",
       "0          1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "1          2  A bereaved Afghan mother took revenge on the T...   \n",
       "2          3  CNBC is reporting Tesla has chosen Nevada as t...   \n",
       "3         12  A 4-inch version of the iPhone 6 is said to be...   \n",
       "4         19  GR editor’s Note\\n\\nThere are no reports in th...   \n",
       "...      ...                                                ...   \n",
       "7059    2586  Remember how much Republicans wanted to repeal...   \n",
       "7060    2586  Remember how much Republicans wanted to repeal...   \n",
       "7061    2586  Remember how much Republicans wanted to repeal...   \n",
       "7062    2586  Remember how much Republicans wanted to repeal...   \n",
       "7063    2586  Remember how much Republicans wanted to repeal...   \n",
       "\n",
       "                                               Headline    Stance     Guess  \n",
       "0     El-Sisi denies claims he'll give Sinai land to...     agree  disagree  \n",
       "1     Afghan Mother Kills 25 Taliban Fighters In Sev...     agree     agree  \n",
       "2     REPORT: Tesla Chooses Nevada For Site Of Its M...   discuss   discuss  \n",
       "3         4-inch iPhone 6 reported to be in development   discuss   discuss  \n",
       "4     Iraqi Army Downs Two British Planes Carrying W...   discuss   discuss  \n",
       "...                                                 ...       ...       ...  \n",
       "7059        A Sign That Obamacare Exchanges Are Failing  disagree     agree  \n",
       "7060  Republicans call Obamacare a 'failure.' These ...     agree  disagree  \n",
       "7061  CBO’s Alternate Facts Show Obamacare is Unsust...  disagree     agree  \n",
       "7062                               Why Obamacare failed  disagree     agree  \n",
       "7063  The success of the Affordable Care Act is a hu...     agree     agree  \n",
       "\n",
       "[7064 rows x 5 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_clean.reset_index()\n",
    "\n",
    "goodagree = 0\n",
    "badagree = 0\n",
    "gooddiscuss = 0\n",
    "baddiscuss = 0\n",
    "gooddisagree = 0\n",
    "baddisagree = 0\n",
    "\n",
    "i = 0\n",
    "for index, row in comp_clean.iterrows():\n",
    "    if(row['Stance'] == row['Guess']):\n",
    "        if(row['Stance'] == 'agree'):\n",
    "            goodagree += 1\n",
    "        elif(row['Stance'] == 'discuss'):\n",
    "            gooddiscuss += 1\n",
    "        elif(row['Stance'] == 'disagree'):\n",
    "            gooddisagree += 1\n",
    "    else:\n",
    "        if(row['Stance'] == 'agree'):\n",
    "            badagree += 1\n",
    "        elif(row['Stance'] == 'discuss'):\n",
    "            baddiscuss += 1\n",
    "        elif(row['Stance'] == 'disagree'):\n",
    "            baddisagree += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agree:  969  -  934\n",
      "Discuss:  3755  -  709\n",
      "Disagree:  262  -  435\n"
     ]
    }
   ],
   "source": [
    "print(\"Agree: \", goodagree, \" - \", badagree)\n",
    "print(\"Discuss: \", gooddiscuss, \" - \", baddiscuss)\n",
    "print(\"Disagree: \", gooddisagree, \" - \", baddisagree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "withcuda",
   "language": "python",
   "name": "withcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
